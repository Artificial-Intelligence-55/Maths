# Colab-ready: ensemble segmented ESPRIT to detect ~20 Riemann zeros  
import numpy as np  
import scipy.linalg, scipy.signal  
from sklearn.cluster import DBSCAN  
import time, math  
  
# === 1) true zeros: ===  
gamma_true = np.array([  
14.134725141, 21.022039639, 25.010857580, 30.424876125, 32.935061588,  
37.586178159, 40.918719012, 43.327073281, 48.005150881, 49.773832478,  
52.970321478, 56.446247697, 59.347044003, 60.831778525, 65.112544048,  
67.079810529, 69.546401711, 72.067158664, 75.704690699, 77.144840069,  
79.337375020, 82.910380854, 84.735492980, 87.425274613, 88.809111208,  
92.491899270, 94.651344041, 95.870634228, 98.831194218, 101.317851006,  
103.725538040, 105.446623182, 107.168611184, 111.029535543, 111.874658586,  
114.320220915, 116.226679103, 118.790782865, 121.370125002, 122.946829294,  
124.256818554, 127.516683880, 129.578704200, 131.087688531, 133.497737203,  
134.756509753, 138.116041613, 139.736208952, 141.123706220, 143.111845808,  
146.000982486, 147.422765344, 150.053520421, 150.925258422, 153.024693811,  
156.112909294, 157.597591818, 158.849988236, 161.188964138, 163.030709686,  
165.537068672, 167.184440155, 169.094514571, 169.911976479, 173.411537239,  
174.754191523, 176.441434297, 178.377407776, 179.916484020, 182.207077520,  
184.874467848, 185.598784077, 187.228923455, 189.416159599, 192.026656360,  
193.079727169, 195.265397198, 196.876482315, 198.015310046, 201.264752151,  
202.493595122, 204.189671803, 205.394697204, 207.906258888, 209.576509790,  
211.690863188, 213.347918838, 214.547045614, 216.169538496, 219.067596348,  
220.714919068, 221.430705798, 224.007000378, 224.983324780, 227.421444120,  
229.337412618, 231.250188700, 231.987235001, 233.693404229, 236.524230232,  
238.478088239, 239.607414443, 241.557661925, 243.025326954, 244.070898211,  
246.446982374, 248.101990147, 249.573247005, 251.014552050, 253.069986009,  
255.269549439, 256.700742684, 258.610439900, 260.289802607, 261.901323932,  
263.884086625, 265.356049562, 266.614959518, 268.937986259, 270.554108341,  
272.239145759, 273.532655184, 275.192223244, 276.869350055, 278.696860095,  
280.401954343, 281.606235513, 283.100436675, 284.835354544, 286.667640392,  
288.122165001, 289.948355991, 291.320170266, 293.224795679, 294.337002964,  
296.200859372, 297.890833313, 299.607572245, 300.897190595, 302.721558627,  
304.308886536, 305.801109561, 307.720175629, 309.184793972, 310.802383652,  
312.403355521, 314.121941395, 315.345983380, 317.152288288, 318.895115900,  
320.140807797, 321.874695043, 323.352717044, 324.837668197, 326.676328239,  
328.311682704, 329.819340847, 331.263092871, 333.037472454, 334.340594251,  
336.135462055, 337.609850380, 338.975964449, 340.784117203, 342.480511559,  
344.079940696, 345.662125186, 347.041990993, 348.706103729, 350.100030341,  
351.772795399, 353.079444776, 354.809503223, 356.332595837, 357.852500566,  
359.652738098, 361.123147424, 362.757017363, 364.232214726, 365.897153330,  
367.234037119, 368.805509681, 370.480368838, 372.035804152, 373.305465099,  
375.117355682, 376.702190498, 378.153593553, 379.685462066, 381.314965595,  
382.816747934, 384.496366907, 385.899839020, 387.423468560, 388.959632290,  
390.507395017, 391.982238846, 393.471447346, 395.147396923, 396.620553150,  
398.013743864, 399.676471226, 401.253467034, 402.661900246, 404.200461533,  
405.742891959, 407.237229299, 408.699195184, 410.287134687, 411.838314720,  
413.310521586, 414.827713247, 416.362499801, 417.854356457, 419.354124518,  
420.949634101, 422.399219544, 423.966659267, 425.495708380, 426.927343978,  
428.429028267, 429.959996931, 431.397558037, 432.849841604, 434.454944661,  
435.919567409, 437.444178633, 438.875702828, 440.401189054, 441.905128310,  
443.370823898, 444.907038329, 446.427006710, 447.951406789, 449.335947087,  
450.884543086, 452.311099667, 453.738950474, 455.210419009, 456.616337800,  
458.150928393, 459.622632708, 461.086058866, 462.569840770, 464.082809138,  
465.480385673, 466.950558556, 468.473485846, 469.933661834, 471.475477276,  
472.939987914, 474.439215708, 475.928416532, 477.389092794, 478.962989344,  
480.370508090, 481.854090698, 483.387410653, 484.827892312, 486.303846505,  
487.789526010, 489.188119361  
], dtype=float)  
gamma_max = float(gamma_true.max())  
  
# === 2) sampling dt  ===  
dt = 0.0001022101682790504  
print("dt =", dt, "gamma_max*dt =", gamma_max*dt)  
  
# === 3) signal generation ===  
N = 50000                  #   
t = np.arange(N) * dt  
print("Generating signal: N =", N)  
signal_full = np.cos(np.outer(t, gamma_true)).sum(axis=1)  
signal_full = signal_full - np.mean(signal_full)  
signal_full = signal_full / np.max(np.abs(signal_full))  
  
# === 4) segmentation & ESPRIT ensemble settings ===  
seg_len = 8000             #   
step = 2000                #
num_seg = max(1, (N - seg_len) // step + 1)  
print("N, seg_len, step, num_seg =", N, seg_len, step, num_seg)  
  
# ensemble of ranks and angle thresholds  
ranks = [40, 60, 80]        # 
angle_thresh_list = [1.2, 1.5]  # rad, 
modulus_tol = 0.05          # | |Î»| - 1 | < modulus_tol  
  
def esprit_segment(y, rank):  
    # Hann window (scipy.signal.windows.hann)  
    w = scipy.signal.windows.hann(len(y))  
    yw = y * w  
    L = len(yw) // 3   # Hankel size control   
    if L < 16:  
        return np.array([])  
    c = yw[:L]  
    r = yw[L-1: L-1 + L]  
    H = scipy.linalg.hankel(c, r)  
    # SVD  
    U, S, Vh = np.linalg.svd(H, full_matrices=False)  
    Us = U[:, :rank]  
    Us1 = Us[:-1, :]  
    Us2 = Us[1:, :]  
    Phi, *_ = np.linalg.lstsq(Us1, Us2, rcond=None)  
    lambdas = np.linalg.eigvals(Phi)  
    return lambdas  
  
start_all = time.time()  
all_candidates = []  
  
for rank in ranks:  
    for angle_thresh in angle_thresh_list:  
        print("Running ensemble with rank =", rank, "angle_thresh =", angle_thresh)  
        seg_times = []  
        cand_local = []  
        for i in range(num_seg):  
            s = i * step  
            seg = signal_full[s:s+seg_len]  
            if len(seg) < seg_len:  
                continue  
            t0 = time.time()  
            lambdas = esprit_segment(seg, rank)  
            seg_times.append(time.time()-t0)  
            if lambdas.size == 0:  
                continue  
            # filter by modulus (remove badly scaled eigenvalues)  
            mask_mod = np.abs(np.abs(lambdas) - 1.0) < modulus_tol  
            lambdas = lambdas[mask_mod]  
            if lambdas.size == 0:  
                continue  
            angles = np.angle(lambdas)  
            # allow both positive and negative small angles (we take abs later)  
            ang_mask = np.abs(angles) < angle_thresh  
            angles = angles[ang_mask]  
            if angles.size == 0:  
                continue  
            gammas = np.abs(angles) / dt  
            # clamp to plausible positive range  
            gammas = gammas[(gammas > 0) & (gammas < gamma_max * 1.2)]  
            cand_local.extend(gammas.tolist())  
        print("  segments used:", len(seg_times), "avg seg time:", np.mean(seg_times) if seg_times else 0,  
              "candidates=", len(cand_local))  
        all_candidates.extend(cand_local)  
  
print("total ensemble candidates:", len(all_candidates), "time:", time.time()-start_all)  
  
# === 5) robust clustering of aggregated candidates ===  
if len(all_candidates) == 0:  
    raise RuntimeError("No candidates found. Relax filters or increase rank/seg_len.")  
  
candidates = np.array(all_candidates)  
# pre-filter too-small/too-large  
candidates = candidates[(candidates > 0) & (candidates < gamma_max*1.2)]  
  
# DBSCAN clustering (eps:0.5-1.0 )  
db = DBSCAN(eps=0.8, min_samples=6)  
labs = db.fit_predict(candidates.reshape(-1,1))  
unique = sorted(set(labs) - {-1})  
centers = []  
counts = []  
for lb in unique:  
    pts = candidates[labs==lb]  
    centers.append(np.median(pts))  
    counts.append(len(pts))  
centers = np.array(centers)  
order = np.argsort(centers)  
centers = centers[order]  
counts = np.array(counts)[order]  
  
print("Detected centers (count):", list(zip(centers.tolist(), counts.tolist())))  
print("Total clusters:", len(centers))  
  
# === 6) top-20 
K = min(20, len(centers))  
matches = []  
for i in range(K):  
    c = centers[i]  
    j = np.argmin(np.abs(gamma_true - c))  
    matches.append((c, float(gamma_true[j]), abs(c - gamma_true[j]), j+1, counts[i]))  
  
print("\nTop-{} matches:".format(K))  
for m in matches:  
    print(f"{m[0]:10.6f} -> true {m[1]:10.6f}, err={m[2]:.6e}, true_idx={m[3]}, cluster_count={m[4]}")  
  
# Save results  
np.savetxt("detected_centers.csv", np.column_stack([centers, counts]), delimiter=",",  
           header="center,count", comments="")  
np.savetxt("all_candidates_sample.csv", candidates[:200], delimiter=",", header="cand", comments="")  
  
print("Elapsed total time (s):", time.time()-start_all)
